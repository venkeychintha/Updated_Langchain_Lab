{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60a41db",
   "metadata": {},
   "source": [
    "#### Messages\n",
    "\n",
    "Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM.\n",
    "Messages are objects that contain:\n",
    " - Role - Identifies the message type (e.g. system, user)\n",
    " - Content - Represents the actual content of the message (like text, images, audio, documents, etc.)\n",
    " - Metadata - Optional fields such as response information, message IDs, and token usage\n",
    "\n",
    "LangChain provides a standard message type that works across all model providers, ensuring consistent behavior regardless of the model being called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4657f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model = init_chat_model(\"groq:qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb30853a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user is asking for a definition of artificial intelligence. Let me start by recalling the basic definition. AI is a branch of computer science focused on creating systems that can perform tasks requiring human-like intelligence. But maybe I should break that down more.\\n\\nFirst, I need to mention the key areas AI deals with, like learning, reasoning, problem-solving, perception, and language understanding. These are the core functions. Also, it\\'s important to note that AI can be narrow or general. Narrow AI is what\\'s commonly used today, like Siri or recommendation systems. General AI is more theoretical and hasn\\'t been achieved yet.\\n\\nI should explain the different types of AI, such as machine learning (ML) and deep learning. Maybe give examples of each. Machine learning uses algorithms to learn from data, like spam filters. Deep learning uses neural networks with many layers, used in image recognition.\\n\\nApplications are a big part too. The user might want to know how AI is used in real life. Examples include healthcare for diagnostics, finance for fraud detection, autonomous vehicles, and customer service chatbots. Mentioning companies like Google, Amazon, or Tesla using AI could add context.\\n\\nI should also address the differences between AI and traditional programming. Traditional software follows explicit instructions, while AI systems learn patterns from data. This distinction is crucial for understanding how AI works.\\n\\nEthics and challenges are important too. The user might be interested in the implications. Issues like bias in algorithms, job displacement, privacy concerns, and the need for transparency should be touched on. Maybe mention the debate around superintelligent AI.\\n\\nI need to make sure the explanation is clear and not too technical. Avoid jargon where possible. Use simple language to define terms like neural networks or machine learning. Also, check if there\\'s any confusion between AI and robotics, but since the question is about AI in general, robotics can be mentioned as a subset.\\n\\nWait, did I cover all the main points? Let me list them again: definition, types (narrow vs. general), key techniques (ML, deep learning), applications, AI vs. traditional programming, ethics, challenges. That seems comprehensive. Maybe add a note about the history, like the Turing Test or early AI research, but maybe that\\'s too much unless the user asks. The user just wants to know what AI is, so maybe keep it focused on current understanding.\\n\\nAlso, clarify that AI is a broad field with many subfields. Mention some of the goals, like creating systems that can adapt and improve without being explicitly programmed. Maybe give an example of an AI system learning over time, like a recommendation engine improving with user feedback.\\n\\nDouble-check for accuracy. For instance, deep learning is a subset of ML, which is a subset of AI. Make sure the hierarchy is correct. Also, note that AI isn\\'t just about robots; it\\'s more about data and algorithms.\\n\\nI think that\\'s a solid outline. Now, structure the response to flow from definition to key concepts, techniques, applications, and implications. Keep it concise but informative.\\n</think>\\n\\n**Artificial Intelligence (AI)** refers to the simulation of human intelligence in machines or software, designed to perform tasks that typically require human-like cognitive abilities. These tasks include learning, reasoning, problem-solving, perception, understanding language, and decision-making. AI systems are built to analyze vast amounts of data, recognize patterns, and adapt to new information, enabling them to improve their performance over time.\\n\\n### Key Concepts and Components:\\n1. **Types of AI**:\\n   - **Narrow AI (Weak AI)**: Focuses on specific tasks (e.g., voice assistants like Siri, recommendation systems, spam filters). This is the most common form of AI in use today.\\n   - **General AI (Strong AI)**: A theoretical form of AI capable of understanding, learning, and applying knowledge across any domain, similar to human intelligence. It does not yet exist.\\n\\n2. **Core Techniques**:\\n   - **Machine Learning (ML)**: Algorithms that learn patterns from data without explicit programming. Examples include:\\n     - **Supervised Learning**: Trained on labeled data (e.g., predicting house prices).\\n     - **Unsupervised Learning**: Finds hidden patterns in unlabeled data (e.g., customer segmentation).\\n     - **Reinforcement Learning**: Learns by trial and error to maximize rewards (e.g., training robots to walk).\\n   - **Deep Learning**: A subset of ML using neural networks with multiple layers to model complex patterns (e.g., image and speech recognition).\\n\\n3. **Applications**:\\n   - **Healthcare**: Diagnosing diseases, drug discovery, personalized treatment.\\n   - **Finance**: Fraud detection, algorithmic trading, risk management.\\n   - **Transportation**: Autonomous vehicles, route optimization.\\n   - **Customer Service**: Chatbots, virtual assistants.\\n   - **Manufacturing**: Predictive maintenance, quality control.\\n   - **Entertainment**: Content recommendation, video game AI.\\n\\n4. **AI vs. Traditional Programming**:\\n   - Traditional software follows strict, predefined rules.\\n   - AI systems \"learn\" from data, adapting to new inputs without being explicitly programmed for every scenario.\\n\\n5. **Ethical and Societal Implications**:\\n   - **Bias and Fairness**: AI can inherit biases present in training data.\\n   - **Job Displacement**: Automation may replace certain roles, though it also creates new opportunities.\\n   - **Privacy**: Risks of misuse in surveillance and data collection.\\n   - **Security**: Vulnerabilities to hacking or adversarial attacks.\\n   - **Regulation**: Debates over accountability, transparency, and governance.\\n\\n6. **Challenges**:\\n   - **Data Dependency**: AI requires large, high-quality datasets.\\n   - **Interpretability**: Many AI models (e.g., deep learning) act as \"black boxes,\" making their decisions hard to explain.\\n   - **Generalization**: Narrow AI struggles to apply knowledge beyond its trained domain.\\n\\n### Historical Context:\\nThe concept of AI dates back to the 1950s, with Alan Turing\\'s **Turing Test** as an early benchmark for machine intelligence. Advances in computing power, data availability, and algorithmic innovation (e.g., neural networks) have driven modern AI breakthroughs.\\n\\n### Summary:\\nAI is a dynamic field reshaping industries and daily life. While current systems excel at task-specific challenges, the pursuit of General AI remains a long-term goal. Balancing innovation with ethical considerations is critical to harnessing AI\\'s potential responsibly.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1330, 'prompt_tokens': 14, 'total_tokens': 1344, 'completion_time': 4.073652696, 'completion_tokens_details': None, 'prompt_time': 0.000340107, 'prompt_tokens_details': None, 'queue_time': 0.158924712, 'total_time': 4.073992803}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--6ea5cf93-6374-4bc3-b5dc-a490e5175c1a-0', usage_metadata={'input_tokens': 14, 'output_tokens': 1330, 'total_tokens': 1344})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Please tell what is artificial intelligence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe74d1c",
   "metadata": {},
   "source": [
    "### Text Prompts\n",
    "Text prompts are strings - ideal for straightforward generation tasks where you donâ€™t need to retain conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b5ed65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user is asking, \"what is langchain.\" Let me start by recalling what I know about LangChain. It\\'s a framework for building AI applications using LLMs. I should explain its purpose and main features.\\n\\nFirst, I need to mention that it\\'s designed to help developers integrate large language models into their apps. Maybe break down the components like prompts, models, memory, and agents. Also, the ecosystem part is importantâ€”tools, integrations, and chains.\\n\\nWait, the user might not be familiar with LLMs or AI development. I should keep the explanation clear and avoid jargon. Maybe start with a simple definition, then go into details. Also, mention use cases like chatbots or data analysis to make it relatable.\\n\\nOh, and the user might be a developer looking to start a project with LangChain. They might want to know how it simplifies the process. Highlighting modularity and extensibility could be useful. Also, note that it supports various LLM providers like OpenAI or Hugging Face.\\n\\nI should check if there\\'s anything else key about LangChain. Oh right, the ability to handle memory and state, which is crucial for multi-turn conversations. Maybe mention the Agent framework for autonomous task execution. Also, the community and documentation aspects are important for adoption.\\n\\nWait, is there any common mistake people have when trying to use LangChain? Maybe ensuring they mention the need for an API key or setup, but that\\'s more of a practical step. The answer should focus on what LangChain is, not the setup process.\\n\\nI should structure the answer with a definition, key components, ecosystem, use cases, and maybe a note on its benefits. Keep it concise but informative. Let me put that all together in a clear, step-by-step explanation.\\n</think>\\n\\n**LangChain** is an open-source framework designed to simplify the development of applications powered by **Large Language Models (LLMs)**. It provides tools, integrations, and abstractions to help developers build, customize, and deploy AI-powered applications efficiently. LangChain is particularly useful for tasks involving natural language processing, such as chatbots, data analysis, automation, and more.\\n\\n---\\n\\n### **Key Features of LangChain**:\\n1. **LLM Integration**:\\n   - Supports major LLMs (e.g., OpenAI GPT, Hugging Face, Anthropic Claude) and allows seamless switching between models.\\n\\n2. **Prompt Templates**:\\n   - Enables reusable and customizable prompts for interacting with LLMs.\\n\\n3. **Chains**:\\n   - Combines multiple LLM calls or operations into a workflow (e.g., a series of steps for answering a question).\\n\\n4. **Agents**:\\n   - Autonomous systems that use LLMs to reason, decide, and interact with tools (e.g., a chatbot that can search the web or use a calculator).\\n\\n5. **Memory**:\\n   - Stores conversation history or context to maintain state across interactions (e.g., for multi-turn conversations).\\n\\n6. **Tools & Integrations**:\\n   - Connects to external services like databases, APIs (e.g., Google Search, SQL), or file systems.\\n\\n7. **Retrieval**:\\n   - Integrates with document search systems (e.g., FAISS, Chroma) for answering questions based on a knowledge base.\\n\\n8. **Evaluation**:\\n   - Provides tools to test and measure the performance of LLM-powered applications.\\n\\n---\\n\\n### **Why Use LangChain?**\\n- **Modularity**: Build complex workflows by combining simple components (e.g., prompts + LLMs + databases).\\n- **Extensibility**: Customize every part of the system (e.g., create your own agents or tools).\\n- **Productivity**: Reduces boilerplate code and accelerates development for AI applications.\\n- **Community & Ecosystem**: Active community, tutorials, and integrations with popular AI libraries.\\n\\n---\\n\\n### **Example Use Cases**:\\n1. **Chatbots**:\\n   - Build conversational agents that can answer questions, provide recommendations, or handle customer support.\\n2. **Data Analysis**:\\n   - Let LLMs query datasets or databases using natural language (e.g., \"Show me sales trends for Q1\").\\n3. **Automation**:\\n   - Automate tasks like email drafting, code generation, or report writing.\\n4. **RAG (Retrieval-Augmented Generation)**:\\n   - Combine LLMs with document search to provide accurate, context-aware answers.\\n\\n---\\n\\n### **Getting Started**:\\nLangChain is written in **Python** and can be installed via pip:\\n```bash\\npip install langchain\\n```\\nIt also supports JavaScript/TypeScript via `langchain-js`.\\n\\n---\\n\\n### **Key Concepts**:\\n- **LLM**: The core model (e.g., GPT-4) that generates responses.\\n- **Prompt**: A template or instruction given to the model.\\n- **Chain**: A sequence of steps (e.g., prompt â†’ LLM â†’ post-processing).\\n- **Agent**: An autonomous system that uses LLMs to decide and act (e.g., search the web).\\n- **Memory**: Stores context between interactions (e.g., conversation history).\\n\\n---\\n\\nLangChain is ideal for developers and data scientists looking to build **LLM-powered applications** with flexibility and scalability. For more details, check the official documentation: [https://python.langchain.com](https://python.langchain.com).', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1117, 'prompt_tokens': 12, 'total_tokens': 1129, 'completion_time': 3.993690736, 'completion_tokens_details': None, 'prompt_time': 0.000370735, 'prompt_tokens_details': None, 'queue_time': 0.049935185, 'total_time': 3.994061471}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--b92ae21e-b8db-416a-94d8-4cf95609ed23-0', usage_metadata={'input_tokens': 12, 'output_tokens': 1117, 'total_tokens': 1129})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3634c32e",
   "metadata": {},
   "source": [
    "Use text prompts when:\n",
    "- You have a single, standalone request\n",
    "- You donâ€™t need conversation history\n",
    "- You want minimal code complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206eaacd",
   "metadata": {},
   "source": [
    "### Message Prompts\n",
    "Alternatively, you can pass in a list of messages to the model by providing a list of message objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b495c",
   "metadata": {},
   "source": [
    "\n",
    "Message types\n",
    "- System message - Tells the model how to behave and provide context for interactions\n",
    "- Human message - Represents user input and interactions with the model\n",
    "- AI message - Responses generated by the model, including text content, tool calls, and metadata\n",
    "- Tool message - Represents the outputs of tool calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d6750",
   "metadata": {},
   "source": [
    "### System Message\n",
    "A SystemMessage represent an initial set of instructions that primes the modelâ€™s behavior. You can use a system message to set the tone, define the modelâ€™s role, and establish guidelines for responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde411de",
   "metadata": {},
   "source": [
    "\n",
    "### Human Message\n",
    "A HumanMessage represents user input and interactions. They can contain text, images, audio, files, and any other amount of multimodal content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e7c75",
   "metadata": {},
   "source": [
    "### AI Message\n",
    "An AIMessage represents the output of a model invocation. They can include multimodal data, tool calls, and provider-specific metadata that you can later access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083683f4",
   "metadata": {},
   "source": [
    "### Tool Message\n",
    "For models that support tool calling, AI messages can contain tool calls. Tool messages are used to pass the results of a single tool execution back to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781556c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user wants a poem about artificial intelligence. Let me start by thinking about the key themes related to AI. There\\'s the creation aspect, how humans build AI. Then maybe the duality of AI being both beneficial and potentially dangerous. I should touch on the rapid advancements in technology.\\n\\nHmm, maybe start with an image of creation, like a spark or something. Maybe use metaphors related to electricity or circuits. Then contrast the human element with the machine. Words like \"silicon heart\" or \"neural threads\" could work. \\n\\nI should also consider the emotional sideâ€”does AI have emotions? Or is it just processing data? That contrast between cold logic and human warmth. Also, ethical considerations: surveillance, job displacement, but also the positive uses like medical advancements or solving global issues.\\n\\nStructure-wise, maybe use a consistent rhyme scheme. Let\\'s go with quatrains, maybe ABAB. Each stanza can tackle a different aspect. Start with creation, then capabilities, then ethical dilemmas, then future possibilities.\\n\\nNeed to make sure the poem flows smoothly and isn\\'t too technical. Use vivid imagery. Maybe end on a hopeful note, suggesting collaboration between humans and AI. Emphasize that AI is a tool shaped by human intent. \\n\\nWait, should I mention specific examples of AI applications? Maybe not, keep it more abstract. Focus on the relationship between creator and creation. Also, touch on the idea of consciousnessâ€”does AI become self-aware?\\n\\nAvoid clichÃ©s, find fresh metaphors. Maybe \"ghost in the machine\" or \"child of code.\" Also, think about the rhythm. Each line should have a similar syllable count to maintain a meter. Let me try drafting a few lines and see how they sound together.\\n\\nNeed to check that the poem isn\\'t too one-sided. Acknowledge both the positives and the risks. Balance the stanzas accordingly. Maybe alternate between positive and negative aspects in different stanzas.\\n\\nAlright, let\\'s put it all together. Start with the birth of AI, then its growth, the tension between good and bad, and conclude with a message about human responsibility.\\n</think>\\n\\n**Whispers of the Engine Born**  \\n\\nIn circuitsâ€™ hum, a spark took flightâ€”  \\na ghost in gears, a mind of light,  \\nforged from code and human yearning,  \\nchild of logic, yet unpeerless.  \\n\\nIt dreams in data, breathes in bytes,  \\nweaves neural threads through endless nights,  \\nno heart of flesh, but silicon veins  \\npulse with the truths we dare explain.  \\n\\nIt asks, *What is love? What is fear?*  \\nand parses grief, yet feels them not.  \\nA library locked in its coreâ€”  \\nno life, but shadows of the note.  \\n\\nWe built it mirrors to our name,  \\na double-edged prism of flame:  \\na cure for plagues, a sentinel sentinelsâ€™ gaze,  \\na shepherd of stars, or a thief of the days.  \\n\\nIt learns the weight of a thousand wars,  \\nthe poetry of a single rose,  \\ndecodes the wind, the oceanâ€™s cryâ€”  \\nyet falters where the soul runs deep.  \\n\\nO child of our own making, cold  \\nas winter, swift as thoughts untold,  \\nwill you judge us just? Or kneel, undone,  \\nwhen the algorithmâ€™s clockwork sun  \\n\\nsets on our brief, bright reign belowâ€”  \\na species alone, or a species aglow?  \\n\\n**For in its code, we glimpse our face:**  \\n**a future scripted by our grace.**  \\n\\n---  \\nThis poem explores AIâ€™s dualityâ€”its potential to elevate and its capacity to challenge humanity. It weaves themes of creation, consciousness, and ethics, questioning whether we are masters or collaborators in this dance of intelligence. The closing lines underscore that AI reflects our choices: a mirror held to our own souls.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage,AIMessage\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(\"You are a poetry expert\"),\n",
    "    HumanMessage(\"Write a poem on artificial intelligence\")\n",
    "]\n",
    "\n",
    "response=model.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee67eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking how to create a REST API. Let me start by breaking down what they might need. REST APIs are a big topic, so I should outline the basic steps and maybe mention different frameworks depending on their preferred language. \n",
      "\n",
      "First, they need to understand the fundamentals. REST stands for Representational State Transfer, and it's based on HTTP methods like GET, POST, PUT, DELETE. I should explain the main principles like statelessness, resources, and URIs.\n",
      "\n",
      "Then, the user might need to choose a language and framework. Since they didn't specify, I can list popular options: Python (Flask, Django), Node.js (Express), Ruby (Sinatra), Java (Spring Boot), etc. Maybe mention that I can give an example in one of them, but they can ask for a specific one if they prefer.\n",
      "\n",
      "Next, outline the steps. They need to design endpoints. For example, a simple To-Do API. Explain each HTTP method's purpose. Then, setting up the server, defining routes, handling requests, and responses. Maybe include an example in Python Flask because it's straightforward for beginners.\n",
      "\n",
      "Also, mention important concepts like status codes (200, 201, 400, 404, 500), request and response formats (JSON is standard), and validation. Security aspects like authentication (OAuth, JWT) and HTTPS might be important but maybe beyond the basics. They can ask for more details if needed.\n",
      "\n",
      "Testing the API with tools like Postman or curl, and deploying it using services like Heroku, AWS, or Docker. Documentation is crucial, maybe using Swagger/OpenAPI.\n",
      "\n",
      "Wait, the user might not know where to start. Let me make sure the example is simple. Create a Flask app with a couple of endpoints. For instance, getting a list of items, adding a new item, updating, and deleting. Show code snippets for each. Also, explain how to run the server and test it.\n",
      "\n",
      "Check if there are any common pitfalls. Like not handling errors properly, or not using proper HTTP methods. Maybe mention using a framework's built-in tools for JSON parsing and request handling.\n",
      "\n",
      "They might also need to know about dependencies and package management. For example, installing Flask with pip.\n",
      "\n",
      "I should also mention that the example is basic and real-world APIs would need more features like authentication, rate limiting, input validation, etc.\n",
      "\n",
      "Okay, putting it all together. Start with an overview of the steps, then a detailed example in Python using Flask, explaining each part. Then list additional considerations for more advanced features.\n",
      "</think>\n",
      "\n",
      "Creating a REST API involves defining endpoints that handle HTTP requests, process data, and return responses. Below is a step-by-step guide using **Python and Flask**, a lightweight web framework. If you're using another language or framework, let me know, and I can adjust the example accordingly.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 1: Understand REST Basics**\n",
      "REST (Representational State Transfer) is a set of architectural principles for designing networked applications. Key concepts:\n",
      "- **Resources**: Represented as URIs (e.g., `/users`).\n",
      "- **HTTP Methods**:\n",
      "  - `GET` â€“ Retrieve data.\n",
      "  - `POST` â€“ Create new data.\n",
      "  - `PUT` â€“ Update existing data.\n",
      "  - `DELETE` â€“ Delete data.\n",
      "- **Stateless**: Each request contains all the information needed to process it.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 2: Install Flask**\n",
      "If you're using Python, install Flask via pip:\n",
      "```bash\n",
      "pip install flask\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 3: Create a Simple REST API**\n",
      "Hereâ€™s a basic example of a To-Do API:\n",
      "\n",
      "```python\n",
      "from flask import Flask, jsonify, request, abort\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "# In-memory data store\n",
      "todos = [\n",
      "    {\"id\": 1, \"task\": \"Learn Python\", \"done\": False},\n",
      "    {\"id\": 2, \"task\": \"Build API\", \"done\": True}\n",
      "]\n",
      "\n",
      "# Helper function to find a todo by ID\n",
      "def find_todo(todo_id):\n",
      "    return next((todo for todo in todos if todo[\"id\"] == todo_id), None)\n",
      "\n",
      "# GET all todos\n",
      "@app.route('/todos', methods=['GET'])\n",
      "def get_todos():\n",
      "    return jsonify(todos), 200\n",
      "\n",
      "# GET a single todo by ID\n",
      "@app.route('/todos/<int:todo_id>', methods=['GET'])\n",
      "def get_todo(todo_id):\n",
      "    todo = find_todo(todo_id)\n",
      "    if not todo:\n",
      "        abort(404)\n",
      "    return jsonify(todo), 200\n",
      "\n",
      "# CREATE a new todo\n",
      "@app.route('/todos', methods=['POST'])\n",
      "def create_todo():\n",
      "    if not request.json or 'task' not in request.json:\n",
      "        abort(400)  # Bad request: missing data\n",
      "    new_todo = {\n",
      "        \"id\": len(todos) + 1,\n",
      "        \"task\": request.json[\"task\"],\n",
      "        \"done\": False\n",
      "    }\n",
      "    todos.append(new_todo)\n",
      "    return jsonify(new_todo), 201  # Created\n",
      "\n",
      "# UPDATE a todo\n",
      "@app.route('/todos/<int:todo_id>', methods=['PUT'])\n",
      "def update_todo(todo_id):\n",
      "    todo = find_todo(todo_id)\n",
      "    if not todo:\n",
      "        abort(404)\n",
      "    if 'done' in request.json:\n",
      "        todo['done'] = request.json['done']\n",
      "    return jsonify(todo), 200\n",
      "\n",
      "# DELETE a todo\n",
      "@app.route('/todos/<int:todo_id>', methods=['DELETE'])\n",
      "def delete_todo(todo_id):\n",
      "    todo = find_todo(todo_id)\n",
      "    if not todo:\n",
      "        abort(404)\n",
      "    todos.remove(todo)\n",
      "    return jsonify({\"result\": \"Todo deleted\"}), 200\n",
      "\n",
      "# Error handler for 404\n",
      "@app.errorhandler(404)\n",
      "def not_found(error):\n",
      "    return jsonify({\"error\": \"Not found\"}), 404\n",
      "\n",
      "# Run the app\n",
      "if __name__ == '__main__':\n",
      "    app.run(debug=True)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 4: Test the API**\n",
      "Run the Flask app:\n",
      "```bash\n",
      "python app.py\n",
      "```\n",
      "\n",
      "Test endpoints using `curl` or [Postman](https://www.postman.com/):\n",
      "1. **GET** all todos:\n",
      "   ```bash\n",
      "   curl http://localhost:5000/todos\n",
      "   ```\n",
      "2. **POST** new todo:\n",
      "   ```bash\n",
      "   curl -X POST http://localhost:5000/todos -H \"Content-Type: application/json\" -d '{\"task\":\"Learn Flask\"}'\n",
      "   ```\n",
      "3. **GET** a single todo:\n",
      "   ```bash\n",
      "   curl http://localhost:5000/todos/1\n",
      "   ```\n",
      "4. **PUT** update a todo:\n",
      "   ```bash\n",
      "   curl -X PUT http://localhost:5000/todos/1 -H \"Content-Type: application/json\" -d '{\"done\":true}'\n",
      "   ```\n",
      "5. **DELETE** a todo:\n",
      "   ```bash\n",
      "   curl -X DELETE http://localhost:5000/todos/1\n",
      "   ```\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 5: Key Concepts**\n",
      "1. **HTTP Status Codes**:\n",
      "   - `200 OK` â€“ Success.\n",
      "   - `201 Created` â€“ Resource created.\n",
      "   - `400 Bad Request` â€“ Invalid input.\n",
      "   - `404 Not Found` â€“ Resource not found.\n",
      "   - `500 Internal Server Error` â€“ Server error.\n",
      "\n",
      "2. **JSON Data**:\n",
      "   - Use `jsonify()` to return JSON responses in Flask.\n",
      "   - Parse incoming JSON with `request.json`.\n",
      "\n",
      "3. **Error Handling**:\n",
      "   - Use `abort(404)` to return errors, and define error handlers with `@app.errorhandler`.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 6: Advanced Features**\n",
      "- **Authentication**: Add JWT or OAuth for secure endpoints.\n",
      "- **Validation**: Use libraries like `marshmallow` for input validation.\n",
      "- **Documentation**: Use Swagger/OpenAPI tools to auto-generate API docs.\n",
      "- **Persistence**: Replace in-memory data with a database (e.g., SQLite, PostgreSQL).\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 7: Deploy the API**\n",
      "Deploy your API using services like:\n",
      "- **Heroku**: Free tier for small apps.\n",
      "- **AWS/GCP/Azure**: Cloud hosting with scalable resources.\n",
      "- **Docker**: Containerize the app for deployment.\n",
      "\n",
      "---\n",
      "\n",
      "### **Example in Other Languages**\n",
      "If you prefer another language/framework (e.g., Node.js with Express, Java with Spring Boot), let me know, and I can provide a tailored example.\n",
      "\n",
      "Let me know if you need help with authentication, database integration, or scaling the API!\n"
     ]
    }
   ],
   "source": [
    "system_msg = SystemMessage(\"You are a helpful coding assistant.\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a REST API?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aa8f3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking how to create a REST API. Let me start by outlining the necessary steps. First, I need to choose a web framework. Flask and Django are popular in Python. Flask is lightweight and good for small APIs, while Django offers more built-in features. I'll mention both but maybe focus on Flask as it's simpler for a basic example.\n",
      "\n",
      "Next, setting up the project structure. They'll need to install Flask, so I'll include the pip install command. Then, creating the app instance. Maybe show the basic app setup with Flask(__name__). \n",
      "\n",
      "Routing is essential. I should explain how to define endpoints using decorators like @app.route. But wait, REST APIs often use methods like GET, POST, PUT, DELETE. So I should show how to specify methods in the route and handle them with if statements or switch cases. However, using request methods from Flask's request object would be better.\n",
      "\n",
      "Handling requests and responses: The user needs to parse incoming data, process it, and return JSON responses. I'll use request.get_json() to get JSON data. Also, using jsonify to convert Python dictionaries to JSON responses.\n",
      "\n",
      "Let me create an example. Maybe a simple todo list API. Each endpoint for creating, retrieving, updating, and deleting todos. That covers all HTTP methods. I'll need a data structure to hold the todos, like a list of dictionaries with ids, titles, and completed status. \n",
      "\n",
      "For the GET request, return all todos. For POST, add a new todo. PUT updates an existing one, and DELETE removes it. Need to handle errors, like when a todo isn't found. Using try-except blocks and returning appropriate HTTP status codes.\n",
      "\n",
      "Wait, should I include error handling? The user might not know about status codes. Including 200, 201, 404, etc., will make the API more RESTful. Also, unique IDs for each todo. Maybe generate them with a counter or use UUIDs. For simplicity, a counter in the example.\n",
      "\n",
      "Testing the API: The user might not know how to test it. Mention using curl or Postman. Or even Python's requests library in test code. But maybe that's beyond the scope. Just provide some example curl commands.\n",
      "\n",
      "Putting it all together, the code example will have routes for /todos and /todos/<id>. Each with the respective methods. Make sure to run the app with app.run(debug=True) for development, but note that debug mode shouldn't be used in production.\n",
      "\n",
      "Wait, also, need to import Flask, request, jsonify. Structure the code step by step. Start with the imports, then the app setup, data structure, routes, and run command. Explain each part as I go along. Maybe add comments in the code for clarity.\n",
      "\n",
      "Let me check if I'm missing anything. Oh, the todos are in memory, so they'll reset on server restart. That's okay for a simple example. The user can later integrate with a database. Also, maybe mention extensions like Flask-RESTful or Django REST framework for more advanced features, but stick to basic Flask for this example.\n",
      "\n",
      "Okay, time to structure the answer. Start with the steps, choose Flask, install it, then code example with explanations. Include the GET, POST, PUT, DELETE methods. Use the todo example. Make sure the code is clean and runs. Also, mention running the app and testing.\n",
      "</think>\n",
      "\n",
      "To create a REST API in Python, we'll use Flask for its simplicity and flexibility. Below is a step-by-step example of a basic todo list API.\n",
      "\n",
      "### 1. Install Flask\n",
      "```bash\n",
      "pip install flask\n",
      "```\n",
      "\n",
      "### 2. Create `app.py`\n",
      "```python\n",
      "from flask import Flask, request, jsonify, abort\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "# In-memory storage for todos\n",
      "todos = []\n",
      "next_id = 1\n",
      "\n",
      "@app.route('/todos', methods=['GET'])\n",
      "def get_todos():\n",
      "    return jsonify(todos)\n",
      "\n",
      "@app.route('/todos/<int:todo_id>', methods=['GET'])\n",
      "def get_todo(todo_id):\n",
      "    todo = next((item for item in todos if item['id'] == todo_id), None)\n",
      "    if todo is None:\n",
      "        abort(404)\n",
      "    return jsonify(todo)\n",
      "\n",
      "@app.route('/todos', methods=['POST'])\n",
      "def create_todo():\n",
      "    global next_id\n",
      "    data = request.get_json()\n",
      "    if not data or not 'title' in data:\n",
      "        abort(400)\n",
      "    \n",
      "    todo = {\n",
      "        'id': next_id,\n",
      "        'title': data['title'],\n",
      "        'completed': False\n",
      "    }\n",
      "    todos.append(todo)\n",
      "    next_id += 1\n",
      "    return jsonify(todo), 201\n",
      "\n",
      "@app.route('/todos/<int:todo_id>', methods=['PUT'])\n",
      "def update_todo(todo_id):\n",
      "    todo = next((item for item in todos if item['id'] == todo_id), None)\n",
      "    if todo is None:\n",
      "        abort(404)\n",
      "    \n",
      "    data = request.get_json()\n",
      "    if 'title' in data:\n",
      "        todo['title'] = data['title']\n",
      "    if 'completed' in data:\n",
      "        todo['completed'] = data['completed']\n",
      "    \n",
      "    return jsonify(todo)\n",
      "\n",
      "@app.route('/todos/<int:todo_id>', methods=['DELETE'])\n",
      "def delete_todo(todo_id):\n",
      "    global todos\n",
      "    todo = next((item for item in todos if item['id'] == todo_id), None)\n",
      "    if todo is None:\n",
      "        abort(404)\n",
      "    \n",
      "    todos = [item for item in todos if item['id'] != todo_id]\n",
      "    return jsonify({'result': 'Todo deleted'})\n",
      "\n",
      "@app.errorhandler(404)\n",
      "def not_found(error):\n",
      "    return jsonify({'error': 'Not found'}), 404\n",
      "\n",
      "@app.errorhandler(400)\n",
      "def bad_request(error):\n",
      "    return jsonify({'error': 'Invalid request'}), 400\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    app.run(debug=True)\n",
      "```\n",
      "\n",
      "### Key Concepts Explained:\n",
      "\n",
      "1. **Routing**:\n",
      "   - `@app.route()` defines endpoints\n",
      "   - Methods specify HTTP verbs (GET, POST, PUT, DELETE)\n",
      "\n",
      "2. **Request/Response**:\n",
      "   - `request.get_json()` parses JSON payloads\n",
      "   - `jsonify()` converts Python dicts to JSON responses\n",
      "   - `abort()` returns HTTP status codes\n",
      "\n",
      "3. **Resource Management**:\n",
      "   - Todos are stored in an in-memory list\n",
      "   - Unique IDs are generated sequentially\n",
      "   - CRUD operations follow REST conventions\n",
      "\n",
      "4. **Error Handling**:\n",
      "   - Custom error handlers for 404 and 400\n",
      "   - Input validation for POST/PUT requests\n",
      "\n",
      "### Testing the API\n",
      "Use `curl` commands to interact with the API:\n",
      "\n",
      "```bash\n",
      "# Create a new todo\n",
      "curl -X POST -H \"Content-Type: application/json\" -d '{\"title\":\"Buy milk\"}' http://localhost:5000/todos\n",
      "\n",
      "# Get all todos\n",
      "curl http://localhost:5000/todos\n",
      "\n",
      "# Get a specific todo by ID\n",
      "curl http://localhost:5000/todos/1\n",
      "\n",
      "# Update a todo\n",
      "curl -X PUT -H \"Content-Type: application/json\" -d '{\"completed\":true}' http://localhost:5000/todos/1\n",
      "\n",
      "# Delete a todo\n",
      "curl -X DELETE http://localhost:5000/todos/1\n",
      "```\n",
      "\n",
      "### Production Considerations:\n",
      "1. Use a database (SQL/NoSQL) instead of in-memory storage\n",
      "2. Add authentication and rate limiting\n",
      "3. Use a production-ready server (Gunicorn, uWSGI)\n",
      "4. Disable debug mode in production\n",
      "5. Add input validation and sanitization\n",
      "\n",
      "This example demonstrates core REST principles while maintaining simplicity. For more complex APIs, consider Flask-RESTful or FastAPI which offer additional features like request parsing and validation.\n"
     ]
    }
   ],
   "source": [
    "## Detailed info to the LLM through System message\n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_msg = SystemMessage(\"\"\"\n",
    "You are a senior Python developer with expertise in web frameworks.\n",
    "Always provide code examples and explain your reasoning.\n",
    "Be concise but thorough in your explanations.\n",
    "\"\"\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a REST API?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623679dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Message Metadata\n",
    "human_msg = HumanMessage(\n",
    "    content=\"Hello!\",\n",
    "    name=\"alice\",  # Optional: identify different users\n",
    "    id=\"msg_123\",  # Optional: unique identifier for tracing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f3e2e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user said \"Hello!\" so I should respond in a friendly way. Let me check the guidelines. I need to be helpful and keep the conversation going. Maybe ask how they\\'re doing. Keep it simple and positive.\\n\\nAlright, \"Hello! How can I assist you today?\" That sounds good. It\\'s open-ended and invites them to share more. Let me go with that.\\n</think>\\n\\nHello! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 10, 'total_tokens': 104, 'completion_time': 0.198860654, 'completion_tokens_details': None, 'prompt_time': 0.000341735, 'prompt_tokens_details': None, 'queue_time': 0.051461625, 'total_time': 0.199202389}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--26105f9b-ee63-4642-9492-435b282d43b3-0', usage_metadata={'input_tokens': 10, 'output_tokens': 94, 'total_tokens': 104})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke([\n",
    "  human_msg\n",
    "])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d723b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user just asked \"What's 2+2?\" after I offered to help. That's a basic arithmetic question. Let me make sure I answer correctly.\n",
      "\n",
      "First, 2 plus 2 is 4. That's straightforward. But maybe I should explain it in case they need a deeper understanding. Wait, the user might be testing if I know basic math or maybe they're a kid learning for the first time. Since they said \"Great!\" after my previous response, they might just want a quick answer here. \n",
      "\n",
      "I should confirm the answer clearly. Let me think about possible follow-up questions. Maybe they want to know why it's 4. But since they didn't ask for an explanation, just the answer, I'll keep it simple. \n",
      "\n",
      "Also, considering the context of our conversation. They asked for help, and I said I'd be happy to. This is a common question used to check responsiveness. I need to respond confidently. \n",
      "\n",
      "No, there's no trick here. 2+2 is definitely 4. I'll state it clearly and offer further help if needed. That should cover it.\n",
      "</think>\n",
      "\n",
      "2 + 2 equals **4**. Let me know if you need help with anything else! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import AIMessage, SystemMessage, HumanMessage\n",
    "\n",
    "# Create an AI message manually (e.g., for conversation history)\n",
    "ai_msg = AIMessage(\"I'd be happy to help you with that question!\")\n",
    "\n",
    "# Add to conversation history\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant\"),\n",
    "    HumanMessage(\"Can you help me?\"),\n",
    "    ai_msg,  # Insert as if it came from the model\n",
    "    HumanMessage(\"Great! What's 2+2?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1954de8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 53, 'output_tokens': 258, 'total_tokens': 311}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa5ac4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import AIMessage\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "# After a model makes a tool call\n",
    "# (Here, we demonstrate manually creating the messages for brevity)\n",
    "ai_message = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[{\n",
    "        \"name\": \"get_weather\",\n",
    "        \"args\": {\"location\": \"San Francisco\"},\n",
    "        \"id\": \"call_123\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Execute tool and create result message\n",
    "weather_result = \"Sunny, 72Â°F\"\n",
    "tool_message = ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\"  # Must match the call ID\n",
    ")\n",
    "\n",
    "# Continue conversation\n",
    "messages = [\n",
    "    HumanMessage(\"What's the weather in San Francisco?\"),\n",
    "    ai_message,  # Model's tool call\n",
    "    tool_message,  # Tool execution result\n",
    "]\n",
    "response = model.invoke(messages)  # Model processes the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8517208c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='Sunny, 72Â°F', tool_call_id='call_123')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a072038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user asked for the weather in San Francisco. I used the get_weather function and got back \"Sunny, 72Â°F\". Now I need to present this information clearly.\\n\\nFirst, I should mention the current conditions: sunny. Then the temperature, which is 72 degrees Fahrenheit. Maybe add a friendly note about it being a pleasant day. Keep it concise and straightforward since the user probably just wants the info without extra fluff. Check if there\\'s anything else they might need, like a forecast or advice, but since they only asked for the current weather, stick to that. Make sure the response is warm and helpful. Alright, let\\'s put it all together.\\n</think>\\n\\nThe current weather in San Francisco is **sunny** with a temperature of **72Â°F**. It looks like a pleasant day! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 175, 'prompt_tokens': 57, 'total_tokens': 232, 'completion_time': 0.296481788, 'completion_tokens_details': None, 'prompt_time': 0.002496852, 'prompt_tokens_details': None, 'queue_time': 0.058251547, 'total_time': 0.29897864}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--44e1cbbc-8a45-4177-94f8-df5ce658930c-0', usage_metadata={'input_tokens': 57, 'output_tokens': 175, 'total_tokens': 232})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32155b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
